{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- one season page:  https://www.basketball-reference.com/leagues/NBA_2020_games.html\n",
    "- one game page: https://www.basketball-reference.com/boxscores/201910220TOR.html\n",
    "- Fastest way to append rows to df: https://stackoverflow.com/questions/57000903/what-is-the-fastest-and-most-efficient-way-to-append-rows-to-a-dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_html = 'https://www.basketball-reference.com/boxscores/201910220TOR.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting all references from the homepage\n",
    "# for link in soup.find_all(\"a\"):\n",
    "#     print(\"Inner Text: {}\".format(link.text))\n",
    "#     print(\"Title: {}\".format(link.get(\"title\")))\n",
    "#     print(\"href: {}\".format(link.get(\"href\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to scrape one game's box scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_scraper(box_table):\n",
    "    '''\n",
    "    Function scprapes one table on game page\n",
    "    '''\n",
    "    rows = []\n",
    "    for idx, child in enumerate(box_table.find_all(\"tr\")):\n",
    "        # Dict for one row\n",
    "        row = {}\n",
    "        # Counter for dictionaries\n",
    "        counter = 0\n",
    "        # Save whether the player is starter\n",
    "        if idx < 7:\n",
    "            # value is 1 if player is starter\n",
    "            row[counter] = 1\n",
    "            counter = counter + 1\n",
    "        else:\n",
    "            row[counter] = 0 # otherwise zero\n",
    "            counter = counter + 1\n",
    "        \n",
    "        for td in child: # iterate through all elements of row\n",
    "            try:\n",
    "                row[counter] = td.text\n",
    "                \n",
    "                if counter == 0: # Getting player references as player IDs\n",
    "                    counter = counter + 1\n",
    "                    row[counter] = td.find('a').get('href')\n",
    "\n",
    "            except:\n",
    "                continue\n",
    "            \n",
    "            counter = counter + 1\n",
    "\n",
    "        if len(row) > 0:\n",
    "            rows.append(row)\n",
    "    # Drop useless elements of table        \n",
    "    rows.pop(7) # additional header for Reserves\n",
    "    rows.pop(0) # header\n",
    "    rows.pop(-1) # total row\n",
    "    return(rows[1:], rows[0]) # giving back the table as a dict and header names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def game_information_collector(soup):\n",
    "    '''\n",
    "    Function collects additional information about games like team ID, score, date or location\n",
    "    Team ID is equal to the end of html\n",
    "    '''\n",
    "    global_inf = []\n",
    "    # Team IDs and name:\n",
    "    for i in soup.find_all('a', attrs = {'itemprop' : 'name'}):\n",
    "        global_inf.append(i.text) #Team name\n",
    "        global_inf.append(i.get('href')) #ID\n",
    "    # Score\n",
    "    gam_res = soup.find_all(\"div\", attrs = {'class' : 'scorebox'})\n",
    "    for i in gam_res[0].find_all('div', attrs = {'class' : \"score\"}):\n",
    "        global_inf.append(i.text)\n",
    "    # date and location\n",
    "    for i in soup.find('div', attrs = {'class' : 'scorebox_meta'}).find_all('div'):\n",
    "            global_inf.append(i.text)\n",
    "    return(global_inf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_page_handler(list_html):\n",
    "    '''\n",
    "    Function scrapes basic statistic of the home and away team as a dictionary\n",
    "    '''\n",
    "    result = requests.get(list_html)\n",
    "    soup = BeautifulSoup(result.content)\n",
    "    \n",
    "    # Global information (team IDs, date, location...)\n",
    "    global_inf = game_information_collector(soup)\n",
    "\n",
    "    counter = 0\n",
    "    # It stores the number of wanted tables\n",
    "    table_needed = []\n",
    "    # Getting the location of necessary tables in the all table list of the game page\n",
    "    for table_id in soup.find_all('table'):\n",
    "        # I need only the basic statistics\n",
    "        if 'game-basic' in table_id.get('id'):\n",
    "            table_needed.append(counter)\n",
    "        counter = counter + 1\n",
    "\n",
    "    # Extract home team's tables\n",
    "    dict_home, header = table_scraper(soup.find_all('table')[table_needed[1]])\n",
    "    for item in dict_home:\n",
    "        item.update( {\"team\":global_inf[2]})\n",
    "        item.update( {\"team_id\":global_inf[3]})\n",
    "        item.update( {\"game_id\":list_html.rsplit('/', 1)[-1]})\n",
    "\n",
    "    # Extract away team's table\n",
    "    dict_away, header = table_scraper(soup.find_all('table')[table_needed[0]])\n",
    "    for item in dict_away:\n",
    "        item.update( {\"team\":global_inf[0]})\n",
    "        item.update( {\"team_id\":global_inf[1]})\n",
    "        item.update( {\"game_id\":list_html.rsplit('/', 1)[-1]})\n",
    "        \n",
    "    # Concatenate tables\n",
    "    return dict_home + dict_away, header"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how it works on a given match url:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_html = 'https://www.basketball-reference.com/boxscores/202012220BRK.html'\n",
    "df = single_page_handler(list_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting links for the games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_score_table_scraper(soup):\n",
    "    '''\n",
    "    I need many box score links from tables like: https://www.basketball-reference.com/leagues/NBA_2020_games.html\n",
    "    Additionally, information can be collected about games. Every row is one game having information about team names and IDs,\n",
    "    game scores, game ID. \n",
    "    '''\n",
    "    rows = []\n",
    "    for child in soup.find_all('table')[0].find_all(\"tr\"):\n",
    "        row = []\n",
    "        counter = -1\n",
    "        for td in child:\n",
    "            counter = counter + 1\n",
    "\n",
    "            try:\n",
    "                if counter in [2, 6, 4]: # references are needed for teams and the box score\n",
    "                    row.append(td.text)\n",
    "                    row.append(td.find('a').get('href'))\n",
    "                else:\n",
    "                    row.append(td.text) # I need only text information in case of \n",
    "            except:\n",
    "                continue\n",
    "                \n",
    "        if len(row) > 0:\n",
    "            rows.append(row)\n",
    "            \n",
    "    return rows[1:] # it gives back the full list of lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_season_links(url, main_url):\n",
    "    '''\n",
    "    It collects all the game level information and box score links for one season\n",
    "    All references per month must be collected. Then references are given to\n",
    "    box_score_table_scraper to create a data frame about game level information for the whole season\n",
    "    '''\n",
    "    result = requests.get(main_url + url)\n",
    "    soup = BeautifulSoup(result.content)\n",
    "    \n",
    "    # Games are grouped by months. The list collects the url of different months\n",
    "    href_season_months = []\n",
    "    for link in soup.find('div', attrs={'class' : 'filter'}).find_all(\"a\"):\n",
    "         href_season_months.append(link.get(\"href\"))\n",
    "    \n",
    "    # It stores game level information as a lists of list\n",
    "    array = []\n",
    "    for href_months in href_season_months:\n",
    "        #print(main_url + href_months)\n",
    "        result = requests.get(main_url + href_months)\n",
    "        soup = BeautifulSoup(result.content)\n",
    "        \n",
    "        array = array + box_score_table_scraper(soup)\n",
    "    \n",
    "    # Transform the result to a dataframe\n",
    "    df = pd.DataFrame(array[1:], columns = ['date', 'hour', 'visitor', 'visitor_id','visitor_score'\n",
    "                                  , 'home', 'home_id', 'home_score', 'box_score', 'box_score_link',\n",
    "                                  'OT', 'att', 'note']).drop(columns = ['box_score', 'note'])\n",
    "    \n",
    "    df = df[(df.home_score != '')]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_one_season_data(url, main_url, saving_path):\n",
    "    '''\n",
    "    It collects all game level information and the linked bo score links using get_one_season_links()\n",
    "    Then it iterates through box score links to get statistics per game\n",
    "    Every game statistic is appended to each other to form a df containing player level information\n",
    "    Finally, it saves player level information for one season\n",
    "    '''\n",
    "    # Creating game level df with box score references\n",
    "    box_score_df = get_one_season_links(url, main_url)\n",
    "    box_score_df = box_score_df[box_score_df.home_score.notna()]\n",
    "    \n",
    "    stats_all_game = []\n",
    "    for box_link in box_score_df.box_score_link:\n",
    "        if isinstance(box_link, str):\n",
    "            stats_per_game, headers = single_page_handler(main_url + box_link)\n",
    "            stats_all_game = stats_all_game + stats_per_game\n",
    "    \n",
    "    stats_all_game = pd.DataFrame.from_dict(stats_all_game)\n",
    "    stats_all_game.columns = ['starter'] + [headers[x] for x in range(22)][1:] + ['team', 'team_id', 'game_id']\n",
    "    \n",
    "    stats_all_game.to_csv(saving_path)\n",
    "    \n",
    "    return(box_score_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving_path = 'C:/Users/Hp/Desktop/year2021/nba game prediction/data/box scores'\n",
    "# url = \"/leagues/NBA_2019_games.html\"\n",
    "# main_url = 'https://www.basketball-reference.com'\n",
    "# proba = get_one_season_data(url, main_url, saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally get the stats of many seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_the_seasons(url, numb_seasons, saving_path, main_url):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    result = requests.get(main_url + url)\n",
    "    soup = BeautifulSoup(result.content)\n",
    "    \n",
    "    season_links = [url]\n",
    "    \n",
    "    for idx, i in enumerate(season_links):\n",
    "        season_links.append(soup.find('div', attrs = {'class' : 'prevnext'}).find('a').get('href'))\n",
    "        result = requests.get(main_url + season_links[-1])\n",
    "        soup = BeautifulSoup(result.content)\n",
    "        if idx > numb_seasons:\n",
    "            break\n",
    "    \n",
    "    #pd.concat([s1, s2], ignore_index=True)\n",
    "    #box_df_list = []\n",
    "    for idx, link in enumerate(season_links):\n",
    "        print(idx)\n",
    "        saving_path_new = saving_path + \"/\" + link.rsplit('/', 1)[-1].rsplit('.')[0] + '.csv'\n",
    "        print(main_url + link)\n",
    "        box = get_one_season_data(link, main_url, saving_path_new)\n",
    "        # box_df_list.append(get_one_season_data(link, main_url, saving_path_new))\n",
    "        box.to_csv(saving_path + \"/\" + link.rsplit('/', 1)[-1].rsplit('.')[0] + 'box_score' +'.csv')\n",
    "\n",
    "    return(box)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://www.basketball-reference.com/leagues/NBA_2021_games.html\n",
      "1\n",
      "https://www.basketball-reference.com/leagues/NBA_2020_games.html\n",
      "2\n",
      "https://www.basketball-reference.com/leagues/NBA_2019_games.html\n",
      "3\n",
      "https://www.basketball-reference.com/leagues/NBA_2018_games.html\n",
      "4\n",
      "https://www.basketball-reference.com/leagues/NBA_2017_games.html\n",
      "5\n",
      "https://www.basketball-reference.com/leagues/NBA_2016_games.html\n",
      "6\n",
      "https://www.basketball-reference.com/leagues/NBA_2015_games.html\n",
      "7\n",
      "https://www.basketball-reference.com/leagues/NBA_2014_games.html\n",
      "Execution time = 8186.268025 seconds\n"
     ]
    }
   ],
   "source": [
    "saving_path = 'C:/Users/Hp/Desktop/year2021/nba game prediction/data/box scores'\n",
    "url = \"/leagues/NBA_2021_games.html\"\n",
    "numb_seasons = 5\n",
    "main_url = 'https://www.basketball-reference.com'\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "scrape_the_seasons(url, numb_seasons, saving_path, main_url)\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print('Execution time = %.6f seconds' % (end_time-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path = 'C:/Users/Hp/Desktop/year2021/nba game prediction/data/box scores/proba.csv'\n",
    "url = '/leagues/NBA_2021_games.html'\n",
    "main_url =  'https://www.basketball-reference.com'\n",
    "df = get_one_season_data(url, main_url, saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement Ideas\n",
    "- There are not enough games in box score table per season. It shoud be 1230 - Actually I have almost enough for full years\n",
    "- in scrape_the_seasons funtion box score tables shoud be binded properly - error occures\n",
    "- box score tables cauld be handled as lists/dicts for simplicity \n",
    "- What are play off games and regular games?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136.43333333333334"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8186/60\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
